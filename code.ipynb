{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Ekstraksi file zip\n",
    "def extract_zip(zip_file_path, extract_to):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "# Path ke file zip dataset\n",
    "zip_file_path = \"hangul_dataset.zip\"\n",
    "\n",
    "# Path untuk mengekstrak dataset\n",
    "extract_to = \"dataset_folder\"\n",
    "\n",
    "# Ekstraksi zip\n",
    "extract_zip(zip_file_path, extract_to)\n",
    "\n",
    "# Load dataset\n",
    "images = []  # List untuk menyimpan gambar\n",
    "labels = []  # List untuk menyimpan label\n",
    "\n",
    "# Loop melalui direktori yang berisi dataset yang telah diekstrak\n",
    "for root, dirs, files in os.walk(extract_to):\n",
    "    for file in files:\n",
    "        if file.endswith(\".png\"):  # Ubah sesuai ekstensi gambar yang Anda miliki\n",
    "            image_path = os.path.join(root, file)\n",
    "            label = os.path.basename(root)  # Menggunakan nama direktori sebagai label\n",
    "            labels.append(label)\n",
    "            img = tf.keras.preprocessing.image.load_img(image_path, color_mode='grayscale', target_size=(28, 28))  # Menggunakan tensorflow.keras\n",
    "            img_array = tf.keras.preprocessing.image.img_to_array(img)  # Menggunakan tensorflow.keras\n",
    "            images.append(img_array)\n",
    "\n",
    "# Konversi menjadi array numpy\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split dataset menjadi training dan testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing data\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Define CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(np.unique(labels)), activation='softmax')  # Number of unique labels\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(rotation_range=10,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1,\n",
    "                             zoom_range=0.1,\n",
    "                             fill_mode='nearest')\n",
    "\n",
    "# Train the model\n",
    "datagen.fit(X_train)\n",
    "history = model.fit(datagen.flow(X_train, y_train_encoded, batch_size=32),\n",
    "                    steps_per_epoch=len(X_train) / 32, epochs=10, validation_data=(X_test, y_test_encoded))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test_encoded)\n",
    "\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
